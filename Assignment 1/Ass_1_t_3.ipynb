{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "273cf5b0-07fc-439f-92e1-315c0ab2667f",
   "metadata": {},
   "source": [
    "# Task 3: Stacked autoencoder (with 3 autoencoders) based pre-training of a DFNN based classifier for Image dataset 3\n",
    "- Model of AANN: 5-layer structure\n",
    "- Mode of learning for AANNs: Mini-batch mode\n",
    "- Stopping criterion: Change in average error below a threshold\n",
    "- Weight update rule: AdaM\n",
    "- Report should include the confusion matrices for training data and test data, for\n",
    "    1. DFNN trained using only labeled data, \n",
    "    2. DFNN trained using a stacked autoencoder pretrained using unlabeled data and finetuned using labeled data. DFNN configuration should be the same in both (a) and (b)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86200174-0cee-4ed1-980c-f618c5a7cec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "323024ba-ebbf-473c-b1e5-a65e6e0b4dad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of labeled training data is (750, 37)\n",
      "\n",
      "The shape of unlabeled training data is (1750, 36)\n",
      "\n",
      "The shape of labeled validation data is (250, 37)\n",
      "\n",
      "The shape of labeled testing data is (250, 37)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "labeled_training_data = pd.read_csv(\"task 3/training_data_set_26_labeled.csv\", header = None)\n",
    "print(f\"The shape of labeled training data is {labeled_training_data.shape}\")\n",
    "print()\n",
    "\n",
    "unlabeled_training_data = pd.read_csv(\"task 3/training_data_set_26_unlabeled.csv\", header = None)\n",
    "print(f\"The shape of unlabeled training data is {unlabeled_training_data.shape}\")\n",
    "print()\n",
    "\n",
    "validation_data = pd.read_csv(\"task 3/validation_data_set_26.csv\", header = None)\n",
    "print(f\"The shape of labeled validation data is {validation_data.shape}\")\n",
    "print()\n",
    "\n",
    "testing_data = pd.read_csv(\"task 3/testing_data_set_26.csv\", header = None)\n",
    "print(f\"The shape of labeled testing data is {testing_data.shape}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80581a22-ed35-4d2a-ba9f-95e07b88f7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        data = torch.FloatTensor(self.df.iloc[idx, :-1])\n",
    "        label = torch.tensor(self.df.iloc[idx, -1], dtype=torch.long)\n",
    "        return data, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13cc2c38-0bed-4c2a-9d2c-9dd068d8335d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(CustomDataset(labeled_training_data), batch_size = 32, shuffle = True)\n",
    "val_dataloader = DataLoader(CustomDataset(validation_data), batch_size = 32, shuffle = False)\n",
    "test_dataloader = DataLoader(CustomDataset(testing_data), batch_size = 32, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a92e651-a119-437a-b39a-8bb424850c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Autoencoder\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, input_dim, encoding_dim):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, encoding_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(encoding_dim, input_dim),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7bde3f35-4cc5-461c-becb-e1b2b621b17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pretraining Autoencoder\n",
    "# Pretrain autoencoders layer by layer\n",
    "def pretrain_autoencoders(data, encoding_dims, batch_size=32, lr=0.001, epochs=50, threshold=1e-4):\n",
    "    dataloader = DataLoader(data, batch_size=batch_size, shuffle=True)\n",
    "    inputs = data\n",
    "    pretrained_weights = []\n",
    "    \n",
    "    for encoding_dim in encoding_dims:\n",
    "        input_dim = inputs.shape[1]\n",
    "        autoencoder = Autoencoder(input_dim, encoding_dim)\n",
    "        criterion = nn.MSELoss()\n",
    "        optimizer = optim.Adam(autoencoder.parameters(), lr=lr)\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            epoch_loss = 0.0\n",
    "            for batch in dataloader:\n",
    "                batch = batch.to(torch.float32)\n",
    "                optimizer.zero_grad()\n",
    "                outputs = autoencoder(batch)\n",
    "                loss = criterion(outputs, batch)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                epoch_loss += loss.item()\n",
    "            \n",
    "            avg_loss = epoch_loss / len(dataloader)\n",
    "            \n",
    "            if epoch % 10 == 0:\n",
    "                print(f\"The average loss is {avg_loss}\", end = \"\\n\")\n",
    "                \n",
    "            if avg_loss < threshold:\n",
    "                break\n",
    "        \n",
    "        pretrained_weights.append(autoencoder.encoder[0].weight.data.clone())\n",
    "        inputs = autoencoder.encoder(torch.tensor(data, dtype=torch.float32)).detach().numpy()\n",
    "    \n",
    "    return pretrained_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ff4a146-b77a-48b6-b08a-e5b7e371f71a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average loss is 0.11666821105913683\n",
      "The average loss is 0.006691737320612777\n",
      "The average loss is 0.006527620071375912\n",
      "The average loss is 0.006220273233272813\n",
      "The average loss is 0.005672135872935707\n"
     ]
    }
   ],
   "source": [
    "# Get the pretrained_weights\n",
    "pretrained_weights = pretrain_autoencoders(unlabeled_training_data.values, [18])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "88e68fcf-4c66-4c33-ad0c-9b9e86cd037e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DFNN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dims, output_dim, pretrained_weights=None):\n",
    "        super(DFNN, self).__init__()\n",
    "        layers = []\n",
    "        previous_dim = input_dim\n",
    "        \n",
    "        for i, hidden_dim in enumerate(hidden_dims):\n",
    "            layer = nn.Linear(previous_dim, hidden_dim)\n",
    "            if pretrained_weights and i < len(pretrained_weights):\n",
    "                layer.weight.data = pretrained_weights[i]\n",
    "            layers.append(layer)\n",
    "            layers.append(nn.ReLU())\n",
    "            previous_dim = hidden_dim\n",
    "        \n",
    "        layers.append(nn.Linear(previous_dim, output_dim))\n",
    "        layers.append(nn.Softmax(dim=1))\n",
    "        self.network = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n",
    "\n",
    "# Train DFNN\n",
    "def train_dfnn(model, train_loader, val_loader, lr=0.001, epochs=50):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for batch_x, batch_y in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_x)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # Evaluate on test data\n",
    "        model.eval()\n",
    "        correct, total = 0, 0\n",
    "        with torch.no_grad():\n",
    "            for batch_x, batch_y in val_loader:\n",
    "                outputs = model(batch_x)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                total += batch_y.size(0)\n",
    "                correct += (predicted == batch_y).sum().item()\n",
    "        \n",
    "        if epoch % 10 == 0: print(f\"Epoch {epoch+1}/{epochs}, Val Accuracy: {100 * correct / total:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "751be037-b0d1-4c1a-b34a-44431832d753",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate confusion matrix\n",
    "def evaluate_model(model, data_loader):\n",
    "    y_true, y_pred = [], []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch_x, batch_y in data_loader:\n",
    "            outputs = model(batch_x)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            y_true.extend(batch_y.numpy())\n",
    "            y_pred.extend(predicted.numpy())\n",
    "    \n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    return cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "22af8bc3-6e55-4499-bd4c-2d93062f48aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train DFNN with pretraining...\n",
      "Epoch 1/100, Val Accuracy: 22.40%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_569768/4074771201.py:10: DeprecationWarning: an integer is required (got type numpy.float64).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  label = torch.tensor(self.df.iloc[idx, -1], dtype=torch.long)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/100, Val Accuracy: 33.20%\n",
      "Epoch 21/100, Val Accuracy: 36.80%\n",
      "Epoch 31/100, Val Accuracy: 38.80%\n",
      "Epoch 41/100, Val Accuracy: 39.60%\n",
      "Epoch 51/100, Val Accuracy: 38.80%\n",
      "Epoch 61/100, Val Accuracy: 41.60%\n",
      "Epoch 71/100, Val Accuracy: 42.40%\n",
      "Epoch 81/100, Val Accuracy: 41.60%\n",
      "Epoch 91/100, Val Accuracy: 40.00%\n",
      "\n",
      "Train DFNN without pretraining...\n",
      "Epoch 1/100, Val Accuracy: 22.40%\n",
      "Epoch 11/100, Val Accuracy: 32.00%\n",
      "Epoch 21/100, Val Accuracy: 34.80%\n",
      "Epoch 31/100, Val Accuracy: 37.20%\n",
      "Epoch 41/100, Val Accuracy: 38.40%\n",
      "Epoch 51/100, Val Accuracy: 39.20%\n",
      "Epoch 61/100, Val Accuracy: 40.80%\n",
      "Epoch 71/100, Val Accuracy: 43.20%\n",
      "Epoch 81/100, Val Accuracy: 42.80%\n",
      "Epoch 91/100, Val Accuracy: 42.80%\n",
      "\n",
      "Evaluating Pretrained\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.41      0.44        51\n",
      "           1       0.39      0.51      0.44        57\n",
      "           2       0.31      0.33      0.32        52\n",
      "           3       0.55      0.48      0.51        44\n",
      "           4       0.32      0.26      0.29        46\n",
      "\n",
      "    accuracy                           0.40       250\n",
      "   macro avg       0.41      0.40      0.40       250\n",
      "weighted avg       0.41      0.40      0.40       250\n",
      "\n",
      "\n",
      "Evaluating Scratch model\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.35      0.40        51\n",
      "           1       0.39      0.54      0.45        57\n",
      "           2       0.29      0.33      0.31        52\n",
      "           3       0.55      0.48      0.51        44\n",
      "           4       0.29      0.22      0.25        46\n",
      "\n",
      "    accuracy                           0.39       250\n",
      "   macro avg       0.40      0.38      0.38       250\n",
      "weighted avg       0.39      0.39      0.38       250\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_569768/4074771201.py:10: DeprecationWarning: an integer is required (got type numpy.float64).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  label = torch.tensor(self.df.iloc[idx, -1], dtype=torch.long)\n"
     ]
    }
   ],
   "source": [
    "# Train DFNN with pretraining\n",
    "print(\"Train DFNN with pretraining...\")\n",
    "dfnn_pretrained = DFNN(input_dim=36, hidden_dims=[18], output_dim=5, pretrained_weights=pretrained_weights)\n",
    "train_dfnn(dfnn_pretrained, train_dataloader, val_dataloader, epochs = 100)\n",
    "print()\n",
    "\n",
    "# Train DFNN without pretraining\n",
    "print(\"Train DFNN without pretraining...\")\n",
    "dfnn_scratch = DFNN(input_dim=36, hidden_dims=[18], output_dim=5)\n",
    "train_dfnn(dfnn_scratch, train_dataloader, val_dataloader, epochs = 100)\n",
    "print()\n",
    "\n",
    "# Evaluate and compare\n",
    "print(\"Evaluating Pretrained\")\n",
    "cm_pretrained = evaluate_model(dfnn_pretrained, test_dataloader)\n",
    "print()\n",
    "\n",
    "print(\"Evaluating Scratch model\")\n",
    "cm_scratch = evaluate_model(dfnn_scratch, test_dataloader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
